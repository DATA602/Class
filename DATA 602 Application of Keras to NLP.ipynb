{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Below is a two-layer network. \\n\\nThe first layer (which actually comes after an input layer) is called the hidden layer\\nand the second one is called the output layer. We need to specify the input dimension\\n(input_dim): we only have 1 unit in the output layer because we are dealing with a binary \\nclassification problem.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Simple Application of Keras to NLP ###\n",
    "\n",
    "\"\"\"Below is a two-layer network. \n",
    "\n",
    "The first layer (which actually comes after an input layer) is called the hidden layer\n",
    "and the second one is called the output layer. We need to specify the input dimension\n",
    "(input_dim): we only have 1 unit in the output layer because we are dealing with a binary \n",
    "classification problem.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In NLP, we always start by cleaning the text or corpus. \n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "def clean_review(text):\n",
    "    # Strip HTML tags\n",
    "    text = re.sub('<[^<]+?>', ' ', text)\n",
    " \n",
    "    # Strip escaped quotes\n",
    "    text = text.replace('\\\\\"', '')\n",
    " \n",
    "    # Strip quotes\n",
    "    text = text.replace('\"', '')\n",
    " \n",
    "    return text\n",
    "\n",
    "# We load the labeledTrainData.tsv including sentiment and reviews\n",
    "df = pd.read_csv('/Users/tonydiana/Downloads/labeledTrainData.tsv', sep='\\t', quoting=3)\n",
    "df['cleaned_review'] = df['review'].apply(clean_review)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['cleaned_review'], df['sentiment'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer is used to convert a collection of text documents to a matrix of token counts.\n",
    "# This is how we create a bag of words or BOW: The bag of words model (BoW model) is a reduced \n",
    "# and simplified representation of a text document from selected parts of the text, based on specific \n",
    "# criteria, such as word frequency.\n",
    "# By understanding how words are positioned and the relative values of word, \n",
    "# we can pick out patterns in a corpus.\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    " \n",
    "vectorizer = CountVectorizer(binary=True, stop_words=stopwords.words('english'), \n",
    "                             lowercase=True, min_df=3, max_df=0.9, max_features=5000)\n",
    "X_train_onehot = vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 500)               2500500   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 501       \n",
      "=================================================================\n",
      "Total params: 2,501,001\n",
      "Trainable params: 2,501,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    " \n",
    "model = Sequential()\n",
    " \n",
    "model.add(Dense(units=500, activation='relu', input_dim=len(vectorizer.get_feature_names())))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "# Adam (adaptive moment estimation) is an adaptive learning rate optimization algorithm designed specifically \n",
    "# for training deep neural networks. Adam is an optimization algorithm that can be used \n",
    "# instead of the classical stochastic gradient descent procedure to update network weights \n",
    "# iterative based in training data. \n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19900 samples, validate on 100 samples\n",
      "Epoch 1/2\n",
      "19900/19900 [==============================] - 7s 334us/step - loss: 0.3481 - accuracy: 0.8550 - val_loss: 0.3939 - val_accuracy: 0.8700\n",
      "Epoch 2/2\n",
      "19900/19900 [==============================] - 6s 319us/step - loss: 0.1853 - accuracy: 0.9295 - val_loss: 0.4249 - val_accuracy: 0.8700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a432d8e50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_onehot[:-100], y_train[:-100], \n",
    "          epochs=2, batch_size=128, verbose=1, \n",
    "          validation_data=(X_train_onehot[-100:], y_train[-100:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 1s 124us/step\n",
      "Accuracy: 0.8679999709129333\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(vectorizer.transform(X_test), y_test, verbose=1)\n",
    "print(\"Accuracy:\", scores[1])  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
